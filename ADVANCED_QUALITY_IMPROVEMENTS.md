# ğŸš€ é«˜çº§æ¢è„¸è´¨é‡æå‡æ–¹æ¡ˆ

## ğŸ“Š å½“å‰è´¨é‡åˆ†æ

### ç°æœ‰ç³»ç»Ÿæ¶æ„
- **æ¨¡å‹**: inswapper_128_fp16.onnx (å•æ¬¡æ¨ç†)
- **å¢å¼º**: GFPGAN (ä¸€æ¬¡æ€§åå¤„ç†)
- **å¤„ç†**: å•è½®æ¢è„¸ + å•è½®å¢å¼º

### è´¨é‡é™åˆ¶
- å•æ¬¡æ¨ç†å¯èƒ½ä¸å¤Ÿç²¾ç»†
- ç¼ºä¹è¿­ä»£ä¼˜åŒ–
- æ²¡æœ‰é’ˆå¯¹æ€§çš„ç‰¹å¾åŒ¹é…
- èåˆç®—æ³•ç›¸å¯¹ç®€å•

## ğŸ¯ è´¨é‡æå‡ç­–ç•¥

### 1. å¤šè½®è¿­ä»£ç²¾ç»†åŒ– ğŸ”„

**æ¦‚å¿µ**: å¤šæ¬¡è¿è¡Œæ¢è„¸ç®—æ³•ï¼Œé€æ­¥ä¼˜åŒ–ç»“æœ

```python
def iterative_face_swap(source_face, target_face, target_frame, iterations=3):
    """å¤šè½®è¿­ä»£æ¢è„¸ï¼Œé€æ­¥æå‡è´¨é‡"""
    
    result_frame = target_frame.copy()
    
    for i in range(iterations):
        logger.info(f"ğŸ”„ æ‰§è¡Œç¬¬ {i+1}/{iterations} è½®æ¢è„¸...")
        
        # æ¯è½®ä½¿ç”¨å‰ä¸€è½®çš„ç»“æœä½œä¸ºè¾“å…¥
        current_target_face = get_one_face(result_frame)
        if current_target_face is None:
            break
            
        # é€æ­¥é™ä½èåˆå¼ºåº¦ï¼Œå¢åŠ ç²¾ç»†åº¦
        blend_ratio = 1.0 - (i * 0.1)  # ç¬¬ä¸€è½®100%ï¼Œé€æ­¥é™ä½
        
        result_frame = swap_face_with_blend_control(
            source_face, 
            current_target_face, 
            result_frame,
            blend_ratio=blend_ratio
        )
        
        # æ¯è½®ååº”ç”¨è½»åº¦å¢å¼º
        if modules.globals.use_face_enhancer:
            result_frame = enhance_face(result_frame)
    
    return result_frame
```

### 2. æ¸è¿›å¼è´¨é‡æå‡ ğŸ“ˆ

**ç­–ç•¥**: ä»ä½åˆ†è¾¨ç‡å¼€å§‹ï¼Œé€æ­¥æå‡åˆ°é«˜åˆ†è¾¨ç‡

```python
def progressive_face_swap(source_face, target_face, target_frame):
    """æ¸è¿›å¼æ¢è„¸ï¼šä½åˆ†è¾¨ç‡â†’é«˜åˆ†è¾¨ç‡"""
    
    original_height, original_width = target_frame.shape[:2]
    
    # é˜¶æ®µ1: ä½åˆ†è¾¨ç‡ç²—ç³™æ¢è„¸ (256x256)
    logger.info("ğŸ”„ é˜¶æ®µ1: ä½åˆ†è¾¨ç‡å¤„ç†...")
    low_res_frame = cv2.resize(target_frame, (256, 256))
    low_res_source_face = resize_face_landmarks(source_face, 256, 256)
    low_res_target_face = get_one_face(low_res_frame)
    
    low_res_result = swap_face(low_res_source_face, low_res_target_face, low_res_frame)
    
    # é˜¶æ®µ2: ä¸­åˆ†è¾¨ç‡ç»†åŒ– (512x512)
    logger.info("ğŸ”„ é˜¶æ®µ2: ä¸­åˆ†è¾¨ç‡å¤„ç†...")
    mid_res_frame = cv2.resize(low_res_result, (512, 512))
    mid_res_source_face = resize_face_landmarks(source_face, 512, 512)
    mid_res_target_face = get_one_face(mid_res_frame)
    
    mid_res_result = swap_face(mid_res_source_face, mid_res_target_face, mid_res_frame)
    
    # é˜¶æ®µ3: åŸåˆ†è¾¨ç‡ç²¾ç»†åŒ–
    logger.info("ğŸ”„ é˜¶æ®µ3: é«˜åˆ†è¾¨ç‡ç²¾ç»†åŒ–...")
    final_frame = cv2.resize(mid_res_result, (original_width, original_height))
    final_source_face = source_face  # ä½¿ç”¨åŸå§‹é«˜åˆ†è¾¨ç‡é¢éƒ¨
    final_target_face = get_one_face(final_frame)
    
    final_result = swap_face(final_source_face, final_target_face, final_frame)
    
    return final_result
```

### 3. æ™ºèƒ½ç‰¹å¾åŒ¹é…ä¼˜åŒ– ğŸ¯

**æ¦‚å¿µ**: åˆ†æé¢éƒ¨ç‰¹å¾ï¼Œä¼˜åŒ–åŒ¹é…åº¦

```python
def feature_aware_face_swap(source_face, target_face, target_frame):
    """åŸºäºç‰¹å¾åˆ†æçš„æ™ºèƒ½æ¢è„¸"""
    
    # åˆ†æé¢éƒ¨ç‰¹å¾ç›¸ä¼¼åº¦
    feature_similarity = analyze_face_similarity(source_face, target_face)
    logger.info(f"ğŸ“Š é¢éƒ¨ç‰¹å¾ç›¸ä¼¼åº¦: {feature_similarity:.2f}")
    
    # æ ¹æ®ç›¸ä¼¼åº¦è°ƒæ•´å¤„ç†ç­–ç•¥
    if feature_similarity > 0.8:
        # é«˜ç›¸ä¼¼åº¦ï¼šä½¿ç”¨ç²¾ç»†æ¨¡å¼
        logger.info("ğŸ¯ æ£€æµ‹åˆ°é«˜ç›¸ä¼¼åº¦é¢éƒ¨ï¼Œä½¿ç”¨ç²¾ç»†æ¨¡å¼...")
        return precise_face_swap(source_face, target_face, target_frame)
    elif feature_similarity > 0.5:
        # ä¸­ç­‰ç›¸ä¼¼åº¦ï¼šä½¿ç”¨æ ‡å‡†æ¨¡å¼ + é¢å¤–è°ƒæ•´
        logger.info("âš–ï¸ ä¸­ç­‰ç›¸ä¼¼åº¦ï¼Œä½¿ç”¨å¢å¼ºæ¨¡å¼...")
        return enhanced_face_swap(source_face, target_face, target_frame)
    else:
        # ä½ç›¸ä¼¼åº¦ï¼šä½¿ç”¨å¤šè½®ä¼˜åŒ–
        logger.info("ğŸ”§ ä½ç›¸ä¼¼åº¦ï¼Œä½¿ç”¨å¤šè½®ä¼˜åŒ–...")
        return iterative_face_swap(source_face, target_face, target_frame, iterations=5)

def analyze_face_similarity(face1, face2):
    """åˆ†æä¸¤ä¸ªé¢éƒ¨çš„ç›¸ä¼¼åº¦"""
    # è®¡ç®—ç‰¹å¾å‘é‡ç›¸ä¼¼åº¦
    embedding1 = face1.embedding
    embedding2 = face2.embedding
    
    # ä½™å¼¦ç›¸ä¼¼åº¦
    similarity = np.dot(embedding1, embedding2) / (
        np.linalg.norm(embedding1) * np.linalg.norm(embedding2)
    )
    
    return similarity
```

### 4. å¤šæ¨¡å‹é›†æˆ ğŸ¤–

**æ¦‚å¿µ**: ä½¿ç”¨å¤šä¸ªä¸åŒçš„æ¨¡å‹ï¼Œç»¼åˆæœ€ä½³ç»“æœ

```python
def ensemble_face_swap(source_face, target_face, target_frame):
    """å¤šæ¨¡å‹é›†æˆæ¢è„¸"""
    
    results = []
    
    # æ¨¡å‹1: æ ‡å‡†inswapper
    logger.info("ğŸ¤– ä½¿ç”¨æ¨¡å‹1: æ ‡å‡†inswapper...")
    result1 = swap_face_with_model(source_face, target_face, target_frame, "inswapper")
    results.append(("inswapper", result1))
    
    # æ¨¡å‹2: é«˜ç²¾åº¦æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if model_available("simswap"):
        logger.info("ğŸ¤– ä½¿ç”¨æ¨¡å‹2: SimSwap...")
        result2 = swap_face_with_model(source_face, target_face, target_frame, "simswap")
        results.append(("simswap", result2))
    
    # é€‰æ‹©æœ€ä½³ç»“æœæˆ–èåˆå¤šä¸ªç»“æœ
    best_result = select_best_result(results, source_face, target_face)
    
    return best_result

def select_best_result(results, source_face, target_face):
    """é€‰æ‹©æˆ–èåˆæœ€ä½³ç»“æœ"""
    
    # è®¡ç®—æ¯ä¸ªç»“æœçš„è´¨é‡åˆ†æ•°
    scored_results = []
    for model_name, result in results:
        quality_score = calculate_quality_score(result, source_face, target_face)
        scored_results.append((quality_score, result, model_name))
        logger.info(f"ğŸ“Š {model_name} è´¨é‡åˆ†æ•°: {quality_score:.3f}")
    
    # é€‰æ‹©æœ€é«˜åˆ†æ•°çš„ç»“æœ
    scored_results.sort(reverse=True)
    best_score, best_result, best_model = scored_results[0]
    
    logger.info(f"ğŸ† é€‰æ‹©æœ€ä½³æ¨¡å‹: {best_model} (åˆ†æ•°: {best_score:.3f})")
    return best_result
```

### 5. é«˜çº§åå¤„ç†ç®¡çº¿ âœ¨

**æ¦‚å¿µ**: å¤šé˜¶æ®µåå¤„ç†ä¼˜åŒ–

```python
def advanced_post_processing(result_frame, source_face, target_face):
    """é«˜çº§åå¤„ç†ç®¡çº¿"""
    
    # é˜¶æ®µ1: è‰²å½©åŒ¹é…
    logger.info("ğŸ¨ é˜¶æ®µ1: è‰²å½©åŒ¹é…...")
    result_frame = match_face_color(result_frame, target_face)
    
    # é˜¶æ®µ2: å…‰ç…§è°ƒæ•´
    logger.info("ğŸ’¡ é˜¶æ®µ2: å…‰ç…§è°ƒæ•´...")
    result_frame = adjust_face_lighting(result_frame, target_face)
    
    # é˜¶æ®µ3: çº¹ç†ç»†åŒ–
    logger.info("ğŸ” é˜¶æ®µ3: çº¹ç†ç»†åŒ–...")
    result_frame = enhance_face_texture(result_frame)
    
    # é˜¶æ®µ4: è¾¹ç¼˜å¹³æ»‘
    logger.info("ğŸŒŠ é˜¶æ®µ4: è¾¹ç¼˜å¹³æ»‘...")
    result_frame = smooth_face_edges(result_frame, target_face)
    
    # é˜¶æ®µ5: æœ€ç»ˆå¢å¼º
    logger.info("âœ¨ é˜¶æ®µ5: GFPGANæœ€ç»ˆå¢å¼º...")
    if modules.globals.use_face_enhancer:
        result_frame = enhance_face(result_frame)
    
    return result_frame

def match_face_color(frame, reference_face):
    """åŒ¹é…é¢éƒ¨è‰²å½©"""
    # æå–é¢éƒ¨åŒºåŸŸçš„è‰²å½©ç»Ÿè®¡
    face_region = extract_face_region(frame, reference_face)
    
    # è®¡ç®—ç›®æ ‡è‰²å½©åˆ†å¸ƒ
    target_mean = np.mean(face_region, axis=(0, 1))
    target_std = np.std(face_region, axis=(0, 1))
    
    # åº”ç”¨è‰²å½©åŒ¹é…
    matched_frame = apply_color_transfer(frame, target_mean, target_std)
    
    return matched_frame
```

## ğŸ› ï¸ å®ç°æ–¹æ¡ˆ

### æ–¹æ¡ˆA: ç®€å•è¿­ä»£ä¼˜åŒ– (æ¨èå¼€å§‹)

```python
def process_image_swap_enhanced(source_url, target_url):
    """å¢å¼ºç‰ˆå›¾ç‰‡æ¢è„¸å¤„ç†"""
    
    # 1. åŸºç¡€å¤„ç†
    source_frame = download_image_from_url(source_url)
    target_frame = download_image_from_url(target_url)
    
    source_face = get_one_face(source_frame)
    target_face = get_one_face(target_frame)
    
    # 2. å¤šè½®è¿­ä»£æ¢è„¸
    logger.info("ğŸš€ å¼€å§‹é«˜è´¨é‡å¤šè½®å¤„ç†...")
    
    # ç¬¬ä¸€è½®ï¼šæ ‡å‡†æ¢è„¸
    result_frame = swap_face(source_face, target_face, target_frame)
    
    # ç¬¬äºŒè½®ï¼šç²¾ç»†åŒ–å¤„ç†
    logger.info("ğŸ”„ ç¬¬äºŒè½®ç²¾ç»†åŒ–...")
    refined_target_face = get_one_face(result_frame)
    if refined_target_face:
        result_frame = swap_face(source_face, refined_target_face, result_frame)
    
    # ç¬¬ä¸‰è½®ï¼šæœ€ç»ˆä¼˜åŒ–
    logger.info("âœ¨ ç¬¬ä¸‰è½®æœ€ç»ˆä¼˜åŒ–...")
    final_target_face = get_one_face(result_frame)
    if final_target_face:
        # ä½¿ç”¨æ›´ç²¾ç»†çš„èåˆå‚æ•°
        result_frame = swap_face_precise(source_face, final_target_face, result_frame)
    
    # 3. é«˜çº§åå¤„ç†
    result_frame = advanced_post_processing(result_frame, source_face, target_face)
    
    # 4. å¤šé‡å¢å¼º
    logger.info("ğŸ¨ åº”ç”¨å¤šé‡å¢å¼º...")
    for i in range(2):  # ä¸¤è½®å¢å¼º
        if modules.globals.use_face_enhancer:
            enhanced = enhance_face(result_frame)
            if enhanced is not None:
                # æ··åˆåŸå§‹å’Œå¢å¼ºç»“æœ
                result_frame = cv2.addWeighted(result_frame, 0.3, enhanced, 0.7, 0)
    
    return result_frame
```

### æ–¹æ¡ˆB: è´¨é‡è¯„åˆ†ä¼˜åŒ–

```python
def quality_driven_face_swap(source_url, target_url, quality_threshold=0.85):
    """åŸºäºè´¨é‡è¯„åˆ†çš„æ¢è„¸ä¼˜åŒ–"""
    
    max_iterations = 5
    current_quality = 0.0
    
    source_frame = download_image_from_url(source_url)
    target_frame = download_image_from_url(target_url)
    
    source_face = get_one_face(source_frame)
    target_face = get_one_face(target_frame)
    
    result_frame = target_frame.copy()
    
    for iteration in range(max_iterations):
        logger.info(f"ğŸ”„ è´¨é‡ä¼˜åŒ–ç¬¬ {iteration + 1} è½®...")
        
        # æ‰§è¡Œæ¢è„¸
        current_target_face = get_one_face(result_frame)
        if current_target_face is None:
            break
            
        result_frame = swap_face(source_face, current_target_face, result_frame)
        
        # è®¡ç®—è´¨é‡åˆ†æ•°
        current_quality = calculate_swap_quality(result_frame, source_face, target_face)
        logger.info(f"ğŸ“Š å½“å‰è´¨é‡åˆ†æ•°: {current_quality:.3f}")
        
        # å¦‚æœè¾¾åˆ°è´¨é‡é˜ˆå€¼ï¼Œæå‰ç»“æŸ
        if current_quality >= quality_threshold:
            logger.info(f"âœ… è¾¾åˆ°è´¨é‡é˜ˆå€¼ {quality_threshold}ï¼Œä¼˜åŒ–å®Œæˆ")
            break
        
        # åº”ç”¨æ¸è¿›å¼å¢å¼º
        if modules.globals.use_face_enhancer:
            result_frame = enhance_face(result_frame)
    
    logger.info(f"ğŸ¯ æœ€ç»ˆè´¨é‡åˆ†æ•°: {current_quality:.3f}")
    return result_frame

def calculate_swap_quality(result_frame, source_face, target_face):
    """è®¡ç®—æ¢è„¸è´¨é‡åˆ†æ•°"""
    
    # æ£€æµ‹ç»“æœä¸­çš„é¢éƒ¨
    result_face = get_one_face(result_frame)
    if result_face is None:
        return 0.0
    
    # è®¡ç®—ä¸æºé¢éƒ¨çš„ç›¸ä¼¼åº¦
    source_similarity = np.dot(result_face.embedding, source_face.embedding)
    
    # è®¡ç®—é¢éƒ¨æ£€æµ‹ç½®ä¿¡åº¦
    detection_confidence = result_face.det_score
    
    # è®¡ç®—å›¾ç‰‡æ¸…æ™°åº¦
    sharpness = calculate_image_sharpness(result_frame)
    
    # ç»¼åˆè´¨é‡åˆ†æ•°
    quality_score = (source_similarity * 0.5 + 
                    detection_confidence * 0.3 + 
                    sharpness * 0.2)
    
    return quality_score
```

## ğŸš€ ç«‹å³å¯å®ç°çš„æ”¹è¿›

### 1. ä¿®æ”¹å½“å‰å¤„ç†å‡½æ•°

è®©æˆ‘ä¸ºæ‚¨å®ç°ç¬¬ä¸€ä¸ªæ”¹è¿›æ–¹æ¡ˆï¼š

```python
# åœ¨ runpod/handler_serverless.py ä¸­æ·»åŠ 
def process_image_swap_from_urls_enhanced(source_url, target_url):
    """å¢å¼ºç‰ˆæ¢è„¸å¤„ç† - å¤šè½®ä¼˜åŒ–"""
    try:
        # åŸºç¡€å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼‰
        # ... [ç°æœ‰ä»£ç ] ...
        
        # å¢å¼ºå¤„ç†ï¼šå¤šè½®ä¼˜åŒ–
        logger.info("ğŸš€ å¼€å§‹å¤šè½®è´¨é‡ä¼˜åŒ–...")
        
        for round_num in range(3):  # ä¸‰è½®ä¼˜åŒ–
            logger.info(f"ğŸ”„ æ‰§è¡Œç¬¬ {round_num + 1} è½®ä¼˜åŒ–...")
            
            # é‡æ–°æ£€æµ‹å½“å‰ç»“æœä¸­çš„é¢éƒ¨
            current_target_face = get_one_face(result_frame)
            if current_target_face is None:
                logger.warning(f"âš ï¸ ç¬¬ {round_num + 1} è½®æœªæ£€æµ‹åˆ°é¢éƒ¨ï¼Œåœæ­¢ä¼˜åŒ–")
                break
            
            # ä½¿ç”¨é€æ¸é™ä½çš„èåˆå¼ºåº¦
            blend_strength = 1.0 - (round_num * 0.15)  # 100% -> 85% -> 70%
            logger.info(f"ğŸ›ï¸ èåˆå¼ºåº¦: {blend_strength:.0%}")
            
            # æ‰§è¡Œç²¾ç»†åŒ–æ¢è„¸
            temp_result = swap_face(source_face, current_target_face, result_frame)
            
            # è´¨é‡æ£€æŸ¥ï¼šå¦‚æœç»“æœæ›´å·®ï¼Œåˆ™ä¿æŒåŸæœ‰ç»“æœ
            if is_result_better(temp_result, result_frame, source_face):
                result_frame = temp_result
                logger.info(f"âœ… ç¬¬ {round_num + 1} è½®ä¼˜åŒ–æˆåŠŸ")
            else:
                logger.info(f"âš ï¸ ç¬¬ {round_num + 1} è½®æœªæ”¹å–„ï¼Œä¿æŒåŸç»“æœ")
            
            # æ¯è½®åè½»åº¦å¢å¼º
            if modules.globals.use_face_enhancer and round_num < 2:
                enhanced = enhance_face(result_frame)
                if enhanced is not None:
                    # æ··åˆåŸå§‹å’Œå¢å¼ºç»“æœ
                    result_frame = cv2.addWeighted(result_frame, 0.6, enhanced, 0.4, 0)
        
        # æœ€ç»ˆå¢å¼º
        logger.info("âœ¨ åº”ç”¨æœ€ç»ˆå¢å¼º...")
        if modules.globals.use_face_enhancer:
            final_enhanced = enhance_face(result_frame)
            if final_enhanced is not None:
                result_frame = final_enhanced
        
        # ... [å…¶ä½™å¤„ç†ä»£ç ] ...
        
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºæ¢è„¸å¤„ç†å¤±è´¥: {e}")
        return {"error": f"Enhanced processing failed: {str(e)}"}
```

è¿™ä¸ªæ–¹æ¡ˆå¯ä»¥ç«‹å³æå‡è´¨é‡ï¼Œæ‚¨æƒ³è¦æˆ‘å®ç°å“ªä¸€ä¸ªï¼Ÿæˆ–è€…æ‚¨æœ‰å…¶ä»–ç‰¹å®šçš„è´¨é‡è¦æ±‚ï¼Ÿ 