#!/usr/bin/env python3
"""
RunPod Serverless Handler - Optimized Version
- å®Œå…¨é˜»æ­¢æ¨¡å‹ä¸‹è½½
- ç®€åŒ–å¤„ç†æµç¨‹
- é€‚ä¸­è¾“å‡ºè´¨é‡
- æ›´å¿«çš„å¯åŠ¨æ—¶é—´
"""

import os
import sys

# ğŸ”§ å¼ºåˆ¶è®¾ç½®æ¨¡å‹è·¯å¾„ï¼Œé˜²æ­¢ä»»ä½•ä¸‹è½½ - å¿…é¡»åœ¨å¯¼å…¥AIåº“ä¹‹å‰
def setup_model_paths_strict():
    """ä¸¥æ ¼è®¾ç½®æ¨¡å‹è·¯å¾„ï¼Œå®Œå…¨é˜»æ­¢ä¸‹è½½"""
    volume_models_dir = "/runpod-volume/faceswap"
    
    # InsightFaceæ¨¡å‹è·¯å¾„
    os.environ['INSIGHTFACE_HOME'] = volume_models_dir
    os.environ['INSIGHTFACE_ROOT'] = volume_models_dir
    
    # GFPGANå’ŒFaceXLibæ¨¡å‹è·¯å¾„
    os.environ['GFPGAN_WEIGHTS_DIR'] = volume_models_dir
    os.environ['FACEXLIB_CACHE_DIR'] = volume_models_dir
    
    # Torchå’ŒHuggingFaceç¼“å­˜
    os.environ['TORCH_HOME'] = volume_models_dir
    os.environ['HUB_CACHE_DIR'] = volume_models_dir
    os.environ['BASICSR_CACHE_DIR'] = volume_models_dir
    
    # åˆ›å»ºInsightFaceç›®å½•ç»“æ„
    insightface_dir = os.path.join(volume_models_dir, '.insightface', 'models')
    os.makedirs(insightface_dir, exist_ok=True)
    
    # å¦‚æœbuffalo_lç›®å½•å­˜åœ¨ï¼Œåˆ›å»ºç¬¦å·é“¾æ¥
    buffalo_source = os.path.join(volume_models_dir, 'buffalo_l')
    buffalo_target = os.path.join(insightface_dir, 'buffalo_l')
    
    if os.path.exists(buffalo_source) and not os.path.exists(buffalo_target):
        try:
            os.symlink(buffalo_source, buffalo_target)
            print(f"âœ… Created buffalo_l symlink: {buffalo_target} -> {buffalo_source}")
        except Exception as e:
            print(f"âš ï¸ Failed to create buffalo_l symlink: {e}")
    
    # åˆ›å»ºGFPGAN weightsç›®å½•å¹¶åˆ›å»ºç¬¦å·é“¾æ¥
    gfpgan_weights_dir = os.path.join(volume_models_dir, 'gfpgan', 'weights')
    os.makedirs(gfpgan_weights_dir, exist_ok=True)
    
    # ä¸ºGFPGANæ¨¡å‹åˆ›å»ºç¬¦å·é“¾æ¥
    gfpgan_models = [
        'detection_Resnet50_Final.pth',
        'parsing_parsenet.pth',
        'detection_mobilenet0.25_Final.pth',
        'alignment_WFLW_4HG.pth',
        'headpose_hopenet.pth',
        'modnet_photographic_portrait_matting.ckpt',
        'recognition_arcface_ir_se50.pth',
        'assessment_hyperIQA.pth'
    ]
    
    for model_name in gfpgan_models:
        source_path = os.path.join(volume_models_dir, model_name)
        target_path = os.path.join(gfpgan_weights_dir, model_name)
        
        if os.path.exists(source_path) and not os.path.exists(target_path):
            try:
                os.symlink(source_path, target_path)
                print(f"âœ… Created GFPGAN symlink: {model_name}")
            except Exception as e:
                print(f"âš ï¸ Failed to create GFPGAN symlink for {model_name}: {e}")
    
    print(f"ğŸ”§ Strict model paths configured:")
    print(f"   INSIGHTFACE_HOME: {os.environ.get('INSIGHTFACE_HOME')}")
    print(f"   GFPGAN_WEIGHTS_DIR: {os.environ.get('GFPGAN_WEIGHTS_DIR')}")

# åœ¨å¯¼å…¥ä»»ä½•AIåº“ä¹‹å‰è®¾ç½®è·¯å¾„
setup_model_paths_strict()

import runpod
import json
import base64
import tempfile
import requests
from io import BytesIO
from PIL import Image
import cv2
import numpy as np
import logging
import time

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# å¯¼å…¥faceswapæ¨¡å—
sys.path.append('/app')
import modules.globals
import modules.core

def verify_models():
    """éªŒè¯Volumeä¸­çš„æ¨¡å‹"""
    logger.info("ğŸ” Verifying models in: /runpod-volume/faceswap")
    
    essential_models = [
        'inswapper_128_fp16.onnx',
        'GFPGANv1.4.pth'
    ]
    
    for model_name in essential_models:
        model_path = os.path.join('/runpod-volume/faceswap', model_name)
        if os.path.exists(model_path):
            size_mb = os.path.getsize(model_path) / (1024 * 1024)
            logger.info(f"âœ… Verified {model_name} ({size_mb:.1f}MB)")
        else:
            logger.error(f"âŒ Missing {model_name}")
            return False
    
    return True

def download_image_from_url(url, max_retries=3):
    """ä»URLä¸‹è½½å›¾ç‰‡"""
    for attempt in range(max_retries):
        try:
            logger.info(f"ğŸ“¥ Downloading image from: {url} (attempt {attempt + 1})")
            
            response = requests.get(url, timeout=30)
            response.raise_for_status()
            
            logger.info(f"ğŸ“‹ Response content-type: {response.headers.get('content-type', 'unknown')}")
            logger.info(f"ğŸ“‹ Response size: {len(response.content)} bytes")
            
            # å°è¯•ç”¨PILæ‰“å¼€å›¾ç‰‡
            try:
                image = Image.open(BytesIO(response.content))
                logger.info(f"ğŸ“ PIL Image format: {image.format}, mode: {image.mode}, size: {image.size}")
                
                # è½¬æ¢ä¸ºRGBæ¨¡å¼
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                
                # è½¬æ¢ä¸ºnumpyæ•°ç»„
                image_array = np.array(image)
                
                # è½¬æ¢ä¸ºBGRæ ¼å¼ï¼ˆOpenCVæ ¼å¼ï¼‰
                if len(image_array.shape) == 3:
                    image_bgr = cv2.cvtColor(image_array, cv2.COLOR_RGB2BGR)
                else:
                    image_bgr = image_array
                
                logger.info(f"âœ… Image downloaded successfully, shape: {image_bgr.shape}")
                return image_bgr
                
            except Exception as e:
                logger.error(f"âŒ Failed to process image: {e}")
                return None
                
        except requests.exceptions.RequestException as e:
            logger.warning(f"âš ï¸ Download attempt {attempt + 1} failed: {e}")
            if attempt < max_retries - 1:
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            continue
    
    logger.error(f"âŒ Failed to download image after {max_retries} attempts")
    return None

def process_image_swap_simple(source_url, target_url, use_face_enhancer=True):
    """ç®€åŒ–çš„å›¾ç‰‡æ¢è„¸å¤„ç†"""
    try:
        # ä¸‹è½½å›¾ç‰‡
        logger.info("ğŸ”„ Starting image downloads...")
        source_frame = download_image_from_url(source_url)
        target_frame = download_image_from_url(target_url)
        
        if source_frame is None or target_frame is None:
            return {"error": "Failed to download images"}
        
        logger.info("âœ… Both images downloaded successfully")
        logger.info(f"ğŸ“ Source image shape: {source_frame.shape}")
        logger.info(f"ğŸ“ Target image shape: {target_frame.shape}")
        
        # æ£€æµ‹äººè„¸
        logger.info("ğŸ” Detecting face in source image...")
        source_face = modules.core.get_one_face(source_frame)
        if source_face is None:
            return {"error": "No face detected in source image"}
        logger.info("âœ… Source face detected successfully")
        
        logger.info("ğŸ” Detecting face in target image...")
        target_face = modules.core.get_one_face(target_frame)
        if target_face is None:
            return {"error": "No face detected in target image"}
        logger.info("âœ… Target face detected successfully")
        
        # ç®€åŒ–çš„å•æ¬¡æ¢è„¸
        logger.info("ğŸš€ Starting face swap...")
        result_frame = modules.core.swap_face(source_face, target_face, target_frame)
        logger.info("âœ… Face swap completed")
        
        # åº”ç”¨é¢éƒ¨å¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if use_face_enhancer:
            try:
                logger.info("ğŸ¨ Applying face enhancement...")
                enhanced_frame = modules.core.enhance_face(target_face, result_frame)
                
                if enhanced_frame is not None:
                    # é€‚åº¦æ··åˆï¼Œé¿å…è¿‡åº¦å¢å¼º
                    face_enhancer_blend = 0.6
                    result_frame = cv2.addWeighted(
                        result_frame, 1 - face_enhancer_blend,
                        enhanced_frame, face_enhancer_blend, 0
                    )
                    logger.info("âœ… Face enhancement applied")
                else:
                    logger.warning("âš ï¸ Face enhancement failed, using original result")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ Face enhancement failed: {e}")
        
        # è½¬æ¢ä¸ºé€‚ä¸­è´¨é‡å›¾ç‰‡
        logger.info("ğŸ“¸ Converting result to optimized quality image...")
        
        # ç¡®ä¿ç»“æœæ˜¯æ­£ç¡®çš„æ•°æ®ç±»å‹
        if result_frame.dtype != np.uint8:
            result_frame = np.clip(result_frame, 0, 255).astype(np.uint8)
        
        # è½¬æ¢é¢œè‰²ç©ºé—´
        if len(result_frame.shape) == 3 and result_frame.shape[2] == 3:
            result_frame_rgb = cv2.cvtColor(result_frame, cv2.COLOR_BGR2RGB)
        else:
            result_frame_rgb = result_frame
        
        # åˆ›å»ºPILå›¾åƒ
        result_image = Image.fromarray(result_frame_rgb)
        
        # é™åˆ¶è¾“å‡ºå°ºå¯¸ï¼Œé¿å…è¿‡å¤§
        max_dimension = 1024  # æœ€å¤§è¾¹é•¿é™åˆ¶
        width, height = result_image.size
        if max(width, height) > max_dimension:
            if width > height:
                new_width = max_dimension
                new_height = int(height * max_dimension / width)
            else:
                new_height = max_dimension
                new_width = int(width * max_dimension / height)
            
            result_image = result_image.resize((new_width, new_height), Image.Resampling.LANCZOS)
            logger.info(f"ğŸ“ Resized output: {width}x{height} -> {new_width}x{new_height}")
        
        # ä¿å­˜ä¸ºé€‚ä¸­è´¨é‡å›¾ç‰‡
        buffer = BytesIO()
        result_image.save(buffer, format='JPEG', quality=85, optimize=True)
        result_data = base64.b64encode(buffer.getvalue()).decode()
        
        logger.info("âœ… Optimized quality result image encoded successfully")
        return {"result": result_data}
        
    except Exception as e:
        logger.error(f"âŒ Face swap processing failed: {e}")
        return {"error": f"Processing failed: {str(e)}"}

def process_detect_faces_simple(image_url):
    """ç®€åŒ–çš„äººè„¸æ£€æµ‹"""
    try:
        logger.info(f"ğŸ” Starting face detection from URL: {image_url}")
        
        # ä¸‹è½½å›¾ç‰‡
        image_frame = download_image_from_url(image_url)
        if image_frame is None:
            return {"error": "Failed to download image"}
        
        logger.info(f"ğŸ“ Image downloaded successfully, shape: {image_frame.shape}")
        
        # æ£€æµ‹äººè„¸
        logger.info("ğŸ” Detecting faces using get_many_faces...")
        faces = modules.core.get_many_faces(image_frame)
        
        if not faces:
            return {"error": "No faces detected in the image"}
        
        logger.info(f"âœ… Detected {len(faces)} face(s)")
        
        # æŒ‰ä½ç½®æ’åºäººè„¸
        def get_face_position(face):
            bbox = face.bbox.astype(int)
            return (bbox[1], bbox[0])  # (y, x) for top-to-bottom, left-to-right
        
        faces.sort(key=get_face_position)
        logger.info("âœ… Faces sorted by position (top-to-bottom, left-to-right)")
        
        # æå–äººè„¸ä¿¡æ¯
        faces_data = []
        for i, face in enumerate(faces):
            try:
                # æå–äººè„¸åŒºåŸŸ
                bbox = face.bbox.astype(int)
                x1, y1, x2, y2 = bbox
                
                # ç¡®ä¿è¾¹ç•Œåœ¨å›¾åƒèŒƒå›´å†…
                h, w = image_frame.shape[:2]
                x1, y1 = max(0, x1), max(0, y1)
                x2, y2 = min(w, x2), min(h, y2)
                
                # æå–äººè„¸å›¾åƒ
                face_image = image_frame[y1:y2, x1:x2]
                
                if face_image.size > 0:
                    # è½¬æ¢ä¸ºRGBå¹¶ç¼–ç 
                    face_rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
                    face_pil = Image.fromarray(face_rgb)
                    
                    # ç¼–ç ä¸ºbase64
                    buffer = BytesIO()
                    face_pil.save(buffer, format='JPEG', quality=90)
                    face_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                    
                    logger.info(f"âœ… Face {i+1} preview extracted successfully")
                    
                    # è®¡ç®—äººè„¸ä¸­å¿ƒç‚¹
                    center_x = (x1 + x2) // 2
                    center_y = (y1 + y2) // 2
                    
                    face_info = {
                        "face_id": i,
                        "bbox": [x1, y1, x2 - x1, y2 - y1],  # [x, y, width, height]
                        "center": [center_x, center_y],
                        "confidence": float(face.det_score),
                        "preview": face_base64
                    }
                    
                    faces_data.append(face_info)
                    logger.info(f"ğŸ‘¤ Face {i+1}: bbox=({x1}, {y1}, {x2-x1}, {y2-y1}), center=({center_x}, {center_y}), confidence={face.det_score:.3f}")
                
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to extract face {i+1}: {e}")
                continue
        
        if not faces_data:
            return {"error": "Failed to extract face data"}
        
        logger.info(f"âœ… Face detection completed: {len(faces_data)} faces detected and sorted by position")
        
        return {
            "faces": faces_data,
            "total_faces": len(faces_data)
        }
        
    except Exception as e:
        logger.error(f"âŒ Face detection failed: {e}")
        return {"error": f"Face detection failed: {str(e)}"}

def handler(job):
    """ä¼˜åŒ–çš„RunPod Serverless Handler"""
    try:
        logger.info("ğŸš€ RunPod Serverless Handler started")
        logger.info(f"ğŸ“‹ Job input: {json.dumps(job['input'], indent=2)}")
        
        # éªŒè¯æ¨¡å‹
        if not verify_models():
            return {"error": "Model verification failed"}
        
        # è®¾ç½®æ¨¡å‹ç›®å½•
        modules.globals.models_dir = '/runpod-volume/faceswap'
        
        # è·å–è¾“å…¥å‚æ•°
        job_input = job['input']
        
        # æ”¯æŒä¸¤ç§å‚æ•°æ ¼å¼
        process_type = job_input.get('process_type') or job_input.get('type')
        
        # æ”¯æŒdetect-faceså’Œdetect_facesä¸¤ç§æ ¼å¼
        if process_type == 'detect-faces':
            process_type = 'detect_faces'
        
        logger.info(f"ğŸ¯ Processing job type: {process_type}")
        
        if process_type == 'single_image':
            # å•å›¾æ¢è„¸
            source_url = job_input.get('source_file') or job_input.get('source_url')
            target_url = job_input.get('target_file') or job_input.get('target_url')
            
            if not source_url or not target_url:
                return {"error": "Missing source_file/source_url or target_file/target_url"}
            
            logger.info("ğŸ“¸ Processing single image face swap")
            logger.info(f"   Source: {source_url}")
            logger.info(f"   Target: {target_url}")
            
            # è·å–é€‰é¡¹
            options = job_input.get('options', {})
            use_face_enhancer = options.get('use_face_enhancer', True)
            
            return process_image_swap_simple(source_url, target_url, use_face_enhancer)
            
        elif process_type == 'detect_faces':
            # äººè„¸æ£€æµ‹
            image_url = job_input.get('image_file') or job_input.get('image_url')
            
            if not image_url:
                return {"error": "Missing image_file/image_url"}
            
            logger.info("ğŸ” Processing face detection")
            logger.info(f"   Image: {image_url}")
            
            return process_detect_faces_simple(image_url)
            
        else:
            return {"error": f"Unsupported process_type: {process_type}"}
            
    except Exception as e:
        logger.error(f"âŒ Handler failed: {e}")
        return {"error": f"Handler failed: {str(e)}"}

if __name__ == "__main__":
    logger.info("ğŸš€ Starting RunPod Serverless with optimized handler...")
    logger.info("ğŸ“ Models directory: /runpod-volume/faceswap")
    logger.info("ğŸ¯ Models ready: True")
    runpod.serverless.start({"handler": handler}) 